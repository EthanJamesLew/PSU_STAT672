{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import GPy\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib import patches\n",
    "%matplotlib inline\n",
    "\n",
    "from safe_learning import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heads-up\n",
    "\n",
    "The following code models an inverted pendulum, and uses a GP model to determine the safe region of attraction (ROA). The following is inteded to illustrate the algorithm, not to be high-performance code. As such, the code will run very slowly, with the main bottleneck being the repeated GP predictions of the dynamics. There are several obvious points that could make the code run faster\n",
    "* A less conservative Lipschitz constant will allow coarser discretizations and therefore faster computations.\n",
    "* Only evaluating states close to the boundary of the safe set, since those are the only states that are able to expand the ROA over time.\n",
    "* Only partially update the GP predictions of the model where needed, rather than everywhere (lots of predictions are at states that are either unsafe and too far away from the current level set, or are already safe and evaluations there have no hope of expanding the ROA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics model\n",
    "\n",
    "We define the dynamics of an inverted pendulum\n",
    "$$\\ddot{\\theta}(t) = \\frac{mgl \\sin(\\theta(t)) + u(t)}{m l^2},$$\n",
    "where $m$ is the mass, $g$ the gravitational constant, $l$ the length of the pendulum, $u$ the control input (torque), and $\\theta$ the angle.\n",
    "\n",
    "The prior model that we use considers no friction, as well as a mass that is $0.5\\,$kg lighter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 2\n",
    "m = 1\n",
    "\n",
    "# 'Wrong' model parameters\n",
    "mass = 0.1\n",
    "friction = 0.\n",
    "length = 0.5\n",
    "gravity = 9.81\n",
    "inertia = mass * length ** 2\n",
    "\n",
    "# True model parameters\n",
    "true_mass = 0.15\n",
    "true_friction = 0.05\n",
    "true_length = length\n",
    "true_inertia = true_mass * true_length ** 2\n",
    "\n",
    "# Input saturation\n",
    "x_max = np.deg2rad(30)\n",
    "u_max = gravity * true_mass * true_length * np.sin(x_max)\n",
    "\n",
    "# LQR cost matrices\n",
    "Q = np.array([[1, 0], [0, 1]], dtype=np.float)\n",
    "R = np.array([[0.1]], dtype=np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "In order for the LQR to return meaningful results, as well as for the GP model to have simpler kernel parameters, we normalize the system dynamics (all dimensions have similar magnitudes).\n",
    "\n",
    "$\\theta$ is normalized withing the maximum controllable angle, $\\dot{\\theta}$ is normalized with the eigenfrequency of the dynamics, and $u$ is normlized with the maximum allowed control input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the cost functions for the LQR computation\n",
    "# x_normalized = inv(Tx) * x\n",
    "Tx = np.diag([x_max, np.sqrt(gravity / length)])\n",
    "Tu = np.array([[u_max]])\n",
    "\n",
    "Tx_inv = np.diag(np.diag(Tx)**(-1))\n",
    "Tu_inv = np.diag(np.diag(Tu)**(-1))\n",
    "                \n",
    "def normalize_x(x):\n",
    "    \"\"\"Normalize x vector\"\"\"\n",
    "    x = np.asarray(x)\n",
    "    return x.dot(Tx_inv)\n",
    "                \n",
    "def denormalize_x(x):\n",
    "    \"\"\"Denormalize x vector\"\"\"\n",
    "    x = np.asarray(x)\n",
    "    return x.dot(Tx)\n",
    "                \n",
    "def normalize_u(u):\n",
    "    \"\"\"Normalize u vector\"\"\"\n",
    "    u = np.asarray(u)\n",
    "    return u.dot(Tu_inv)\n",
    "\n",
    "def denormalize_u(u):\n",
    "    \"\"\"Denormalize u vector\"\"\"\n",
    "    u = np.asarray(u)\n",
    "    return u.dot(Tu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics functions\n",
    "\n",
    "Here we define the physical dynamics, as well as the prior dynamics, which are a linearization of the true, nonlinear model with wrong parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nonlinear dynamics\n",
    "def ode(x, u):\n",
    "    \"\"\"True ode of the dynamics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: np.array\n",
    "        2D array with one, normalized state\n",
    "        at each column\n",
    "    u: np.array\n",
    "        2D array with one, normalized input\n",
    "        at each column\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x_dot: np.array\n",
    "        The normalized derivative of the dynamics\n",
    "    \"\"\"\n",
    "    # Denormalize\n",
    "    x = denormalize_x(np.atleast_2d(x))\n",
    "    u = denormalize_u(np.asarray(u))\n",
    "                \n",
    "    # Physical dynamics\n",
    "    x_dot = np.hstack([x[:, [1]],\n",
    "                      (gravity / true_length * np.sin(x[:, [0]]) +\n",
    "                       u / true_inertia\n",
    "                       - true_friction / true_inertia * x[:, [1]])])\n",
    "                \n",
    "    # Normalize\n",
    "    return normalize_x(x_dot)\n",
    "\n",
    "# Linearized dynamics\n",
    "A = np.array([[0, 1],\n",
    "              [gravity / length, -friction / inertia]])\n",
    "\n",
    "B = np.array([[0],\n",
    "              [1 / inertia]])\n",
    "\n",
    "# Normalize linear dynamics\n",
    "An = Tx_inv.dot(A.dot(Tx))\n",
    "Bn = Tx_inv.dot(B.dot(Tu))\n",
    "    \n",
    "# Obtain LQR controlelr gain and cost-to-go matrix\n",
    "Kn, Pn = lqr(An, Bn, Q, R)\n",
    "\n",
    "\n",
    "u_max_norm = normalize_u(u_max)\n",
    "                \n",
    "def control_law(x):\n",
    "    \"\"\"LQR controller with bounded (normalized) inputs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: np.array\n",
    "        2D array with one normalized state on each column\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    u: np.array\n",
    "        2D array with normalized inputs on each column\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    u = -x.dot(Kn.T)\n",
    "    np.clip(u, -u_max_norm, u_max_norm, out=u)\n",
    "    return u\n",
    "\n",
    "def true_dynamics(x):\n",
    "    \"\"\"Return the true closed-loop, normalized dynamics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: np.array\n",
    "        2D array with one normalized state on each column\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x_dot: np.array\n",
    "        2D array with normalized derivative states on each column\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    u = control_law(x)\n",
    "    return ode(x, u)\n",
    "\n",
    "def prior_dynamics(x):\n",
    "    \"\"\"Return the linearized, closed-loop, prior, normalized dynamics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: np.array\n",
    "        2D array with one normalized state on each column\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x_dot: np.array\n",
    "        2D array with normalized derivative states on each column\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    u = control_law(x)\n",
    "    return x.dot(An.T) + u.dot(Bn.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization\n",
    "\n",
    "We discretize the state into a grid world. Since we will use the conservative, theoretical Lipschitz constant of $\\dot{V}(x)$ from Lemma 5, we have to discretize very finely. In practice, one may be tempted to pick larger values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Discretization constant\n",
    "tau = 0.002\n",
    "\n",
    "# x_min, x_max, accuracy\n",
    "grid_param = [(-0.5, 0.5, tau),\n",
    "              (-0.5, 0.5, tau)]\n",
    "\n",
    "# Used to plot the safe set later\n",
    "extent = np.array([grid_param[0][0], grid_param[0][1],\n",
    "                   grid_param[1][0], grid_param[1][1]])\n",
    "\n",
    "# Define a grid with combinations of states\n",
    "grid = [np.arange(*x) for x in grid_param]\n",
    "num_samples = [len(x) for x in grid]\n",
    "grid = combinations(grid)\n",
    "\n",
    "# Initial safe set\n",
    "grid_true = denormalize_x(grid)\n",
    "S0 = np.logical_and(np.abs(grid_true[:, 0]) < np.deg2rad(5),\n",
    "                    np.abs(grid_true[:, 1]) < np.deg2rad(10))\n",
    "\n",
    "if not np.any(S0):\n",
    "    print('No initial safe points!')\n",
    "print('Grid size: {0} combinations in {1}x{2} discretized with tau={3}'\n",
    "      .format(len(grid), extent[:2], extent[2:], tau))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian process model of the error\n",
    "\n",
    "We define the state vector $\\mathbf{x} = [\\mathbf{x}_1, \\mathbf{x}_2] = [\\theta, \\dot{\\theta}]$, so that the dynamics can be written as\n",
    "$$\n",
    "\\dot{\\mathbf{x}} =\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "\\mathbf{x}_2 \\\\\n",
    "\\frac{mgl \\sin(\\mathbf{x}_1) + \\tau}{m l^2}\n",
    "\\end{matrix} \\right]\n",
    "$$\n",
    "\n",
    "The first part of this equation says that the angle is equal to the integrated angular velocity. This is a intuitively true, irrespective of model errors. As such, we only learn the model error of the second part of the dynamics. That is\n",
    "$$\\dot{\\mathbf{x}} =\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "\\mathbf{x}_2 \\\\\n",
    "\\frac{mgl \\sin(\\mathbf{x}_1) + \\tau}{m l^2} + g_\\pi(\\mathbf{x})\n",
    "\\end{matrix} \\right]\n",
    "$$\n",
    "\n",
    "As a kernel we choose $k(x,x') = k_{\\mathrm{linear}}(x, x') * k_{\\mathrm{Matern}}(x, x')$, the product of a linear and a Matern kernel. This encodes nonlinear functions with linearly increasing amplitude. For more details what this kernel encodes, see the one-dimensional example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mean function for the GP with the prior dynamics\n",
    "mf = GPy.core.Mapping(2, 1)\n",
    "mf.f = lambda x: prior_dynamics(x)[:, [1]]\n",
    "mf.update_gradients = lambda a,b: None\n",
    "\n",
    "# Matern kernel multiplied with linear kernel\n",
    "kernel = (GPy.kern.Matern32(input_dim=2, lengthscale=.2, variance=5, name='radial') *\n",
    "          GPy.kern.Linear(input_dim=2, name='linear', variances=1))\n",
    "\n",
    "# Measurement model\n",
    "likelihood = GPy.likelihoods.Gaussian(variance=0.05**2)\n",
    "\n",
    "# GP with initial measurement at (0, 0), 0\n",
    "gp = GPy.core.GP(np.array([[0, 0]]), np.array([[0]]),\n",
    "                 kernel, likelihood, mean_function=mf)\n",
    "\n",
    "\n",
    "def predict_model(gp, x):\n",
    "    \"\"\"Predict the model using the gp dynamics\n",
    "    \n",
    "    Given that the model error only affects the second derivative,\n",
    "    the first state has zero variance and is equal to the prior model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    gp: GPy.core.GP\n",
    "        The GP model of the dynamics (including prior)\n",
    "    x: np.array\n",
    "        2D array. Each column has one state at which\n",
    "        to predict the dynamics\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    mean: np.array\n",
    "        The mean dynamics at x\n",
    "    var: np.array\n",
    "        Variance of the dynamics at x\n",
    "    \"\"\"\n",
    "    gp_mean, gp_var = gp._raw_predict(x)\n",
    "    # Augment with deterministic model for first state\n",
    "    gp_mean = np.hstack([prior_dynamics(x)[:, [0]], gp_mean])\n",
    "    gp_var = np.hstack([np.zeros_like(gp_var), gp_var])\n",
    "    return gp_mean, gp_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lipschitz constant\n",
    "\n",
    "The Lipschitz constant is defined via the high-probability Lipschitz constant of the GP model, as well as the linear dynamics. Importantly, here we use the local Lipschitz constants. Since the kernel we have choosen implies increasing Lipschitz constants with distance from the origin. the worst-case Lipschitz constant would be too conservative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lyapunov function:\n",
    "V, dV = quadratic_lyapunov_function(grid, Pn)\n",
    "V_max = np.max(V)\n",
    "accuracy = V_max / 1e10\n",
    "\n",
    "# Lipschitz constants of Lyapunov function\n",
    "B_dV = L_V = np.max(np.abs(dV), axis=1)\n",
    "L_dV = np.max(Pn)\n",
    "\n",
    "# Kernel parameters\n",
    "kernel_lengthscale = np.min(gp.kern.radial.lengthscale).squeeze()\n",
    "kernel_var = gp.kern.radial.variance.values.squeeze()\n",
    "linear_var = gp.kern.linear.Kdiag(grid).squeeze()\n",
    "\n",
    "# Dynamics Lipschitz constants\n",
    "L_g = 2 * np.sqrt(kernel_var * linear_var) / kernel_lengthscale\n",
    "L_f = np.max(np.abs(An - Bn.dot(Kn)))\n",
    "\n",
    "# Function bounds\n",
    "B_g = 2 * np.sqrt(kernel_var * linear_var)\n",
    "B_f = prior_dynamics(grid)[:, 1]\n",
    "\n",
    "L = (B_g + B_f) * L_dV + B_dV * (L_g + L_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True safe levelset\n",
    "\n",
    "To get an intuition about the task at hand, we compute the maximum, safe level set (ROA) according to the true and prior dynamics. The learning algorithm only has access to the prior dynamics model, not the true model!\n",
    "\n",
    "The plot shows the maximum level set (orange), and the region where $\\dot{V}$ is sufficiently small (red). It can be seen that the prior model estimates a safe region that is too large, since it considers a lighter mass. Also, the third plot shows that we cannot recover the maximum level set with the learning method, since it considers $\\dot{V}(x) < -L\\tau$, rather than $\\dot{V}(x) < 0$. For finer discretizations the two sets will get closer and closer to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V_dot_true = compute_v_dot_upper_bound(dV, true_dynamics(grid), None)\n",
    "V_dot_prior = compute_v_dot_upper_bound(dV, prior_dynamics(grid), None)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 20))\n",
    "\n",
    "S_true = get_safe_set(V_dot_true, 0, S0=None)\n",
    "axes[0].imshow(np.reshape(S_true, num_samples).T, extent=extent, origin='lower')\n",
    "c_true = find_max_levelset(S_true, V, accuracy)\n",
    "axes[0].imshow(np.reshape(V <= c_true, num_samples).T, extent=extent, origin='lower', alpha=0.3, cmap='viridis')\n",
    "axes[0].set_title('True safe set (V_dot < 0)')\n",
    "\n",
    "S_prior = get_safe_set(V_dot_prior, 0, S0=S0)\n",
    "c_prior = find_max_levelset(S_prior, V, accuracy)\n",
    "axes[1].imshow(np.reshape(S_prior, num_samples).T, extent=extent, origin='lower')\n",
    "axes[1].set_title('Prior safe set (V_dot < 0)')\n",
    "axes[1].imshow(np.reshape(V < c_prior, num_samples).T, extent=extent, origin='lower', alpha=0.3, cmap='viridis')\n",
    "\n",
    "S_true_L = get_safe_set(V_dot_true, -L*tau, S0=S0)\n",
    "c_true_L = find_max_levelset(S_true_L, V, accuracy)\n",
    "axes[2].imshow(np.reshape(S_true_L, num_samples).T, extent=extent, origin='lower')\n",
    "axes[2].set_title('True safe set (V_dot < -L*tau)')\n",
    "axes[2].imshow(np.reshape(V < c_true_L, num_samples).T, extent=extent, origin='lower', alpha=0.3, cmap='viridis')\n",
    "plt.show()\n",
    "\n",
    "print('Number of true safe points:   {0}/{3}\\n'\n",
    "      'Number of prior safe points:  {1}/{3}\\n'\n",
    "      'Number of finite safe points: {2}/{3}\\n'.format(np.count_nonzero(V < c_true),\n",
    "                                                       np.count_nonzero(V < c_prior),\n",
    "                                                       np.count_nonzero(V < c_true_L),\n",
    "                                                       grid.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online learning\n",
    "\n",
    "Now let us see how the learning algorithm performs. We compute the maximum level set based on the GP estimate of the dynamics, and sample the most uncertain state within for 100 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V, dV = quadratic_lyapunov_function(grid, Pn)\n",
    "    \n",
    "def update_gp():\n",
    "    dynamics_mean, dynamics_var = predict_model(gp, grid)\n",
    "    V_dot = compute_v_dot_upper_bound(dV, dynamics_mean, dynamics_var, beta=2.)\n",
    "    S = get_safe_set(V_dot, -L*tau, S0=S0)\n",
    "    c = find_max_levelset(S, V, accuracy)\n",
    "    S[:] = V <= c\n",
    "    max_id = np.argmax(dynamics_var[S, 1])\n",
    "    max_state = grid[S][[max_id], :].copy()\n",
    "    gp.set_XY(np.vstack([gp.X, max_state]),\n",
    "              np.vstack([gp.Y, true_dynamics(max_state)[:, [1]]]))\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Warning: This is non-optimized, academic code. Executing the following cell may take roughly a minute on a decent laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try to import a nice progress bar\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except:\n",
    "    tqdm = lambda x: x\n",
    "    \n",
    "# Update the GP model 100 times\n",
    "for i in tqdm(range(100)):\n",
    "    S = update_gp()\n",
    "    \n",
    "print('Number of estimated safe points: {0}% relative to true dynamics with V_dot < 0'\n",
    "      .format(np.count_nonzero(S) / np.count_nonzero(V < c_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results\n",
    "\n",
    "We plot the resulting estimate. By restricting ourselves to the levelset $\\dot{V} \\leq -L \\tau$, we cannot reach the true safe set. However, if we pick a less conservative Lipschitz constant and discretize at a finer rate, the two will approach each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def denorm_ellipse(P, level):\n",
    "    \"\"\"Return the ellipse _bounds, but denormalized.\"\"\"\n",
    "    x0, x1_u, x1_l = ellipse_bounds(P, level)\n",
    "    return Tx[0,0] * x0, Tx[1,1] * x1_u, Tx[1,1] * x1_l\n",
    "\n",
    "c_est = find_max_levelset(S, V, accuracy)\n",
    "colors = ['b', 'm', 'r']\n",
    "\n",
    "plt.fill_between(*denorm_ellipse(Pn, c_prior), color=colors[0], alpha=0.5)\n",
    "plt.fill_between(*denorm_ellipse(Pn, c_true), color=colors[1], alpha=0.5)\n",
    "plt.fill_between(*denorm_ellipse(Pn, c_est), color=colors[2], alpha=0.5)\n",
    "\n",
    "patch0 = patches.Patch(color=colors[0], alpha=0.5, label='Prior safe set')\n",
    "patch1 = patches.Patch(color=colors[1], alpha=0.5, label='True safe set')\n",
    "patch2 = patches.Patch(color=colors[2], alpha=0.5, label='Estimated safe set')\n",
    "\n",
    "legs = [patch0, patch1, patch2]\n",
    "labels = [x.get_label() for x in legs]\n",
    "leg = plt.legend(legs, labels, loc=3, borderaxespad=0)\n",
    "\n",
    "data = denormalize_x(gp.X[1:, :])\n",
    "plt.plot(data[:, 0], data[:, 1], 'x')\n",
    "\n",
    "plt.xlabel(r'Angle $\\theta$')\n",
    "plt.ylabel(r'Angular velocity $\\dot{\\theta}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
